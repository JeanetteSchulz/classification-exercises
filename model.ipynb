{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7842d52b",
   "metadata": {},
   "source": [
    "# Model Exercise\n",
    "<hr style=\"border:2px solid red\"> </hr>\n",
    "<hr style=\"border:2px solid red\"> </hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b2d008c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import acquire\n",
    "\n",
    "from pydataset import data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6dbdbb",
   "metadata": {},
   "source": [
    "### Using the titanic data, do the following:\n",
    "### 1. What is your baseline prediction? What is your baseline accuracy? remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). When you make those predictions, what is your accuracy? This is your baseline accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad0d170d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>is_female</th>\n",
       "      <th>embark_town_Cherbourg</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>572</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.3875</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>430</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>858</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19.2583</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>186</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.5000</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>206</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.8500</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     passenger_id  survived  pclass     sex  sibsp  parch     fare  \\\n",
       "572           572         1       1    male      0      0  26.3875   \n",
       "430           430         1       1    male      0      0  26.5500   \n",
       "858           858         1       3  female      0      3  19.2583   \n",
       "186           186         1       3  female      1      0  15.5000   \n",
       "206           206         0       3    male      1      0  15.8500   \n",
       "\n",
       "     embark_town  alone  is_female  embark_town_Cherbourg  \\\n",
       "572  Southampton      1          0                      0   \n",
       "430  Southampton      1          0                      0   \n",
       "858    Cherbourg      0          1                      1   \n",
       "186   Queenstown      0          1                      0   \n",
       "206  Southampton      0          0                      0   \n",
       "\n",
       "     embark_town_Queenstown  embark_town_Southampton  \n",
       "572                       0                        1  \n",
       "430                       0                        1  \n",
       "858                       0                        0  \n",
       "186                       1                        0  \n",
       "206                       0                        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Acquiring my titanic dataset\n",
    "titanic_train, titanic_validate, titanic_test = acquire.prep_titanic(acquire.get_titanic_data()) \n",
    "titanic_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "616775b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU CAN'T HAVE ANY STRING COLUMNS!!!\n",
    "# Drop the original columns we encoded\n",
    "titanic_train = titanic_train.drop(columns=[\"sex\", \"embark_town\"])\n",
    "titanic_validate = titanic_validate.drop(columns=[\"sex\", \"embark_town\"])\n",
    "titanic_test = titanic_test.drop(columns=[\"sex\", \"embark_town\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9328b5f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    307\n",
       "1    191\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Okay, now to figure out baseline predictions\n",
    "titanic_train.survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a6e238d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy:  61.65 %\n"
     ]
    }
   ],
   "source": [
    "# I clearly want 'did not survive' or '0' to be my baseline prediction\n",
    "# since there are only two values, the highest value count will also be the mode!\n",
    "\n",
    "baseline = (titanic_train.survived.mode() )[0] # I designated element because of what it returns without designation\n",
    "\n",
    "baseline_accuracy = ( titanic_train.survived == baseline ).mean()\n",
    "print(\"Baseline accuracy: \", round(baseline_accuracy * 100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdfffbe",
   "metadata": {},
   "source": [
    "> <b>Answer 1:</b>\n",
    ">\n",
    "> <b>Baseline Prediction: '0' which means they did not survive</b>\n",
    ">\n",
    "> <b>Baseline Accuracy: 61.65%<b/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c00e5c",
   "metadata": {},
   "source": [
    "### 2. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3f9481a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First I need to create the X & y version of train\n",
    "# where y is a series with just the target variable and X are all the features. \n",
    "\n",
    "X_train = titanic_train.drop(columns=[\"survived\"])\n",
    "y_train = titanic_train.survived\n",
    "\n",
    "X_validate = titanic_validate.drop(columns=[\"survived\"])\n",
    "y_validate = titanic_validate.survived\n",
    "\n",
    "X_test = titanic_test.drop(columns=[\"survived\"])\n",
    "y_test = titanic_test.survived\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b021ef4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>is_female</th>\n",
       "      <th>embark_town_Cherbourg</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>572</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.3875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>430</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>858</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19.2583</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>186</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>206</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.8500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     passenger_id  pclass  sibsp  parch     fare  alone  is_female  \\\n",
       "572           572       1      0      0  26.3875      1          0   \n",
       "430           430       1      0      0  26.5500      1          0   \n",
       "858           858       3      0      3  19.2583      0          1   \n",
       "186           186       3      1      0  15.5000      0          1   \n",
       "206           206       3      1      0  15.8500      0          0   \n",
       "\n",
       "     embark_town_Cherbourg  embark_town_Queenstown  embark_town_Southampton  \n",
       "572                      0                       0                        1  \n",
       "430                      0                       0                        1  \n",
       "858                      1                       0                        0  \n",
       "186                      0                       1                        0  \n",
       "206                      0                       0                        1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize \n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eef6380c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "572    1\n",
       "430    1\n",
       "858    1\n",
       "186    1\n",
       "206    0\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize \n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99463d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Model\n",
    "\n",
    "# Create the Decision Tree object with desired hyper-parameters.\n",
    "# for classification you can change the algorithm to gini or entropy (information gain).  \n",
    "# Default is gini.\n",
    "\n",
    "classifier = DecisionTreeClassifier(max_depth=3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf8056ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model \n",
    "classifier = classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c91703b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Predictions/ Use the model\n",
    "# This is where the model makes predictions, based on training set obeservations\n",
    "y_predictions = classifier.predict(X_train)\n",
    "y_predictions[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ae6647d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4       , 0.6       ],\n",
       "       [0.8       , 0.2       ],\n",
       "       [0.38235294, 0.61764706],\n",
       "       [0.38235294, 0.61764706],\n",
       "       [0.89855072, 0.10144928]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimate Probability\n",
    "# Estimate the probability of each passenger's survival, using the training data.\n",
    "predict_probability = classifier.predict_proba(X_train)\n",
    "predict_probability[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edfb5ca",
   "metadata": {},
   "source": [
    "### 3. Evaluate your in-sample results using the model score, confusion matrix, and classification report.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "659ea925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 81.73%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Model\n",
    "# Compute the Accuracy\n",
    "\n",
    "# Remember that Accuracy is the number of correct predictions over the number of total instances \n",
    "# that have been evaluated.\n",
    "\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}%'\n",
    "      .format(classifier.score(X_train, y_train) * 100 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdbdb5c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>258</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  258   49\n",
       "1   42  149"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion Matrix \n",
    "# The rows are whether the passenger actual survived (in the y_train)\n",
    "# The columns are what the y_predictions predicted \n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_train, y_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6dd6df36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_predictions)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26c157d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.840391</td>\n",
       "      <td>0.850082</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.752525</td>\n",
       "      <td>0.780105</td>\n",
       "      <td>0.766067</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.817269</td>\n",
       "      <td>0.817269</td>\n",
       "      <td>0.817269</td>\n",
       "      <td>0.817269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.806263</td>\n",
       "      <td>0.810248</td>\n",
       "      <td>0.808075</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.818780</td>\n",
       "      <td>0.817269</td>\n",
       "      <td>0.817860</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.860000  0.840391  0.850082  307.000000\n",
       "1              0.752525  0.780105  0.766067  191.000000\n",
       "accuracy       0.817269  0.817269  0.817269    0.817269\n",
       "macro avg      0.806263  0.810248  0.808075  498.000000\n",
       "weighted avg   0.818780  0.817269  0.817860  498.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification Report \n",
    "report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "pd.DataFrame(report).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7be77e",
   "metadata": {},
   "source": [
    "### 4. Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "147cb383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.73\n",
      "True Positive: 86.0 %\n",
      "False Positive: 24.75 %\n",
      "True Negative: 75.25 %\n",
      "False Negative: 14.0 %\n",
      "Precision: 84.04 %\n",
      "Recall: 86.0 %\n",
      "F1-Score: 85.01 %\n",
      "Positive Support: 300\n",
      "Negative Support: 198\n"
     ]
    }
   ],
   "source": [
    "# Positive: 'did not survive'\n",
    "# Negative: 'survived'\n",
    "\n",
    "# Assign values from Confusion Matrix:\n",
    "TP = 258\n",
    "FP = 49\n",
    "FN = 42\n",
    "TN = 149\n",
    "\n",
    "# Computations:\n",
    "accuracy = (TP + TN)/(TP + FP + FN + TN)\n",
    "print(\"Accuracy:\", round(accuracy*100,2))\n",
    "\n",
    "true_positive = TP/(TP+FN)\n",
    "print(\"True Positive:\", round(true_positive*100, 2) , \"%\")\n",
    "\n",
    "false_positive = FP/(FP+TN)\n",
    "print(\"False Positive:\", round(false_positive*100, 2) , \"%\")\n",
    "\n",
    "true_negative = TN/(TN+FP)\n",
    "print(\"True Negative:\", round(true_negative*100, 2) , \"%\")\n",
    "\n",
    "false_negative = FN/(FN+TP)\n",
    "print(\"False Negative:\", round(false_negative*100, 2) , \"%\")\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "print(\"Precision:\", round(precision*100, 2) , \"%\")\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "print(\"Recall:\", round(recall*100, 2) , \"%\")\n",
    "\n",
    "# f1-score: The balanced harmonic mean of Recall and Precision, giving both metrics equal weight. \n",
    "# The higher the F-Measure is, the better. \n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(\"F1-Score:\", round(f1_score*100, 2) , \"%\")\n",
    "\n",
    "# Support: number of occurrences of each class in where y is true.\n",
    "pos_support = TP + FN\n",
    "print(\"Positive Support:\", pos_support)\n",
    "\n",
    "neg_support = FP + TN\n",
    "print(\"Negative Support:\", neg_support)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078df2e6",
   "metadata": {},
   "source": [
    "### 5. Run through steps 2-4 using a different max_depth value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4a03c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree with max depth of 1\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.800000    0.728324    0.7751    0.764162      0.772510\n",
      "recall       0.846906    0.659686    0.7751    0.753296      0.775100\n",
      "f1-score     0.822785    0.692308    0.7751    0.757546      0.772742\n",
      "support    307.000000  191.000000    0.7751  498.000000    498.000000\n",
      "\n",
      "Accuracy of Decision Tree classifier on training set: 77.51%\n",
      "Accuracy: 77.51\n",
      "True Positive: 80.0 %\n",
      "False Positive: 27.17 %\n",
      "True Negative: 72.83 %\n",
      "False Negative: 20.0 %\n",
      "Precision: 84.69 %\n",
      "Recall: 80.0 %\n",
      "F1-Score: 82.28 %\n",
      "Positive Support: 325\n",
      "Negative Support: 173\n",
      "===============================================================================\n",
      "Tree with max depth of 2\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.800000    0.728324    0.7751    0.764162      0.772510\n",
      "recall       0.846906    0.659686    0.7751    0.753296      0.775100\n",
      "f1-score     0.822785    0.692308    0.7751    0.757546      0.772742\n",
      "support    307.000000  191.000000    0.7751  498.000000    498.000000\n",
      "\n",
      "Accuracy of Decision Tree classifier on training set: 77.51%\n",
      "Accuracy: 77.51\n",
      "True Positive: 80.0 %\n",
      "False Positive: 27.17 %\n",
      "True Negative: 72.83 %\n",
      "False Negative: 20.0 %\n",
      "Precision: 84.69 %\n",
      "Recall: 80.0 %\n",
      "F1-Score: 82.28 %\n",
      "Positive Support: 325\n",
      "Negative Support: 173\n",
      "===============================================================================\n",
      "Tree with max depth of 3\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.860000    0.752525  0.817269    0.806263      0.818780\n",
      "recall       0.840391    0.780105  0.817269    0.810248      0.817269\n",
      "f1-score     0.850082    0.766067  0.817269    0.808075      0.817860\n",
      "support    307.000000  191.000000  0.817269  498.000000    498.000000\n",
      "\n",
      "Accuracy of Decision Tree classifier on training set: 81.73%\n",
      "Accuracy: 81.73\n",
      "True Positive: 86.0 %\n",
      "False Positive: 24.75 %\n",
      "True Negative: 75.25 %\n",
      "False Negative: 14.0 %\n",
      "Precision: 84.04 %\n",
      "Recall: 86.0 %\n",
      "F1-Score: 85.01 %\n",
      "Positive Support: 300\n",
      "Negative Support: 198\n",
      "===============================================================================\n",
      "Tree with max depth of 4\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.838235    0.860759  0.845382    0.849497      0.846874\n",
      "recall       0.928339    0.712042  0.845382    0.820190      0.845382\n",
      "f1-score     0.880989    0.779370  0.845382    0.830179      0.842015\n",
      "support    307.000000  191.000000  0.845382  498.000000    498.000000\n",
      "\n",
      "Accuracy of Decision Tree classifier on training set: 84.54%\n",
      "Accuracy: 84.54\n",
      "True Positive: 83.82 %\n",
      "False Positive: 13.92 %\n",
      "True Negative: 86.08 %\n",
      "False Negative: 16.18 %\n",
      "Precision: 92.83 %\n",
      "Recall: 83.82 %\n",
      "F1-Score: 88.1 %\n",
      "Positive Support: 340\n",
      "Negative Support: 158\n",
      "===============================================================================\n",
      "Tree with max depth of 5\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.878505    0.858757  0.871486    0.868631      0.870931\n",
      "recall       0.918567    0.795812  0.871486    0.857189      0.871486\n",
      "f1-score     0.898089    0.826087  0.871486    0.862088      0.870474\n",
      "support    307.000000  191.000000  0.871486  498.000000    498.000000\n",
      "\n",
      "Accuracy of Decision Tree classifier on training set: 87.15%\n",
      "Accuracy: 87.15\n",
      "True Positive: 87.85 %\n",
      "False Positive: 14.12 %\n",
      "True Negative: 85.88 %\n",
      "False Negative: 12.15 %\n",
      "Precision: 91.86 %\n",
      "Recall: 87.85 %\n",
      "F1-Score: 89.81 %\n",
      "Positive Support: 321\n",
      "Negative Support: 177\n",
      "===============================================================================\n",
      "Tree with max depth of 6\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.886503    0.895349  0.889558    0.890926      0.889896\n",
      "recall       0.941368    0.806283  0.889558    0.873825      0.889558\n",
      "f1-score     0.913112    0.848485  0.889558    0.880799      0.888325\n",
      "support    307.000000  191.000000  0.889558  498.000000    498.000000\n",
      "\n",
      "Accuracy of Decision Tree classifier on training set: 88.96%\n",
      "Accuracy: 88.96\n",
      "True Positive: 88.65 %\n",
      "False Positive: 10.47 %\n",
      "True Negative: 89.53 %\n",
      "False Negative: 11.35 %\n",
      "Precision: 94.14 %\n",
      "Recall: 88.65 %\n",
      "F1-Score: 91.31 %\n",
      "Positive Support: 326\n",
      "Negative Support: 172\n",
      "===============================================================================\n",
      "Tree with max depth of 7\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.917460    0.901639  0.911647    0.909550      0.911392\n",
      "recall       0.941368    0.863874  0.911647    0.902621      0.911647\n",
      "f1-score     0.929260    0.882353  0.911647    0.905807      0.911270\n",
      "support    307.000000  191.000000  0.911647  498.000000    498.000000\n",
      "\n",
      "Accuracy of Decision Tree classifier on training set: 91.16%\n",
      "Accuracy: 91.16\n",
      "True Positive: 91.75 %\n",
      "False Positive: 9.84 %\n",
      "True Negative: 90.16 %\n",
      "False Negative: 8.25 %\n",
      "Precision: 94.14 %\n",
      "Recall: 91.75 %\n",
      "F1-Score: 92.93 %\n",
      "Positive Support: 315\n",
      "Negative Support: 183\n",
      "===============================================================================\n",
      "Tree with max depth of 8\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.911854    0.958580  0.927711    0.935217      0.929775\n",
      "recall       0.977199    0.848168  0.927711    0.912683      0.927711\n",
      "f1-score     0.943396    0.900000  0.927711    0.921698      0.926752\n",
      "support    307.000000  191.000000  0.927711  498.000000    498.000000\n",
      "\n",
      "Accuracy of Decision Tree classifier on training set: 92.77%\n",
      "Accuracy: 92.77\n",
      "True Positive: 91.19 %\n",
      "False Positive: 4.14 %\n",
      "True Negative: 95.86 %\n",
      "False Negative: 8.81 %\n",
      "Precision: 97.72 %\n",
      "Recall: 91.19 %\n",
      "F1-Score: 94.34 %\n",
      "Positive Support: 329\n",
      "Negative Support: 169\n",
      "===============================================================================\n",
      "Tree with max depth of 9\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.952381    0.961749  0.955823    0.957065      0.955974\n",
      "recall       0.977199    0.921466  0.955823    0.949332      0.955823\n",
      "f1-score     0.964630    0.941176  0.955823    0.952903      0.955635\n",
      "support    307.000000  191.000000  0.955823  498.000000    498.000000\n",
      "\n",
      "Accuracy of Decision Tree classifier on training set: 95.58%\n",
      "Accuracy: 95.58\n",
      "True Positive: 95.24 %\n",
      "False Positive: 3.83 %\n",
      "True Negative: 96.17 %\n",
      "False Negative: 4.76 %\n",
      "Precision: 97.72 %\n",
      "Recall: 95.24 %\n",
      "F1-Score: 96.46 %\n",
      "Positive Support: 315\n",
      "Negative Support: 183\n",
      "===============================================================================\n",
      "Tree with max depth of 10\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.967846    0.967914  0.967871    0.967880      0.967872\n",
      "recall       0.980456    0.947644  0.967871    0.964050      0.967871\n",
      "f1-score     0.974110    0.957672  0.967871    0.965891      0.967805\n",
      "support    307.000000  191.000000  0.967871  498.000000    498.000000\n",
      "\n",
      "Accuracy of Decision Tree classifier on training set: 96.79%\n",
      "Accuracy: 96.79\n",
      "True Positive: 96.78 %\n",
      "False Positive: 3.21 %\n",
      "True Negative: 96.79 %\n",
      "False Negative: 3.22 %\n",
      "Precision: 98.05 %\n",
      "Recall: 96.78 %\n",
      "F1-Score: 97.41 %\n",
      "Positive Support: 311\n",
      "Negative Support: 187\n",
      "===============================================================================\n",
      "Tree with max depth of 11\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.971519    1.000000  0.981928    0.985759      0.982442\n",
      "recall       1.000000    0.952880  0.981928    0.976440      0.981928\n",
      "f1-score     0.985554    0.975871  0.981928    0.980713      0.981840\n",
      "support    307.000000  191.000000  0.981928  498.000000    498.000000\n",
      "\n",
      "Accuracy of Decision Tree classifier on training set: 98.19%\n",
      "Accuracy: 98.19\n",
      "True Positive: 97.15 %\n",
      "False Positive: 0.0 %\n",
      "True Negative: 100.0 %\n",
      "False Negative: 2.85 %\n",
      "Precision: 100.0 %\n",
      "Recall: 97.15 %\n",
      "F1-Score: 98.56 %\n",
      "Positive Support: 316\n",
      "Negative Support: 182\n",
      "===============================================================================\n",
      "Tree with max depth of 12\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.996711    0.979381   0.98996    0.988046      0.990064\n",
      "recall       0.986971    0.994764   0.98996    0.990868      0.989960\n",
      "f1-score     0.991817    0.987013   0.98996    0.989415      0.989974\n",
      "support    307.000000  191.000000   0.98996  498.000000    498.000000\n",
      "\n",
      "Accuracy of Decision Tree classifier on training set: 99.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.0\n",
      "True Positive: 99.67 %\n",
      "False Positive: 2.06 %\n",
      "True Negative: 97.94 %\n",
      "False Negative: 0.33 %\n",
      "Precision: 98.7 %\n",
      "Recall: 99.67 %\n",
      "F1-Score: 99.18 %\n",
      "Positive Support: 304\n",
      "Negative Support: 194\n",
      "===============================================================================\n",
      "Tree with max depth of 13\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.993506    0.994737  0.993976    0.994122      0.993978\n",
      "recall       0.996743    0.989529  0.993976    0.993136      0.993976\n",
      "f1-score     0.995122    0.992126  0.993976    0.993624      0.993973\n",
      "support    307.000000  191.000000  0.993976  498.000000    498.000000\n",
      "\n",
      "Accuracy of Decision Tree classifier on training set: 99.40%\n",
      "Accuracy: 99.4\n",
      "True Positive: 99.35 %\n",
      "False Positive: 0.53 %\n",
      "True Negative: 99.47 %\n",
      "False Negative: 0.65 %\n",
      "Precision: 99.67 %\n",
      "Recall: 99.35 %\n",
      "F1-Score: 99.51 %\n",
      "Positive Support: 308\n",
      "Negative Support: 190\n",
      "===============================================================================\n",
      "Tree with max depth of 14\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.996753    1.000000  0.997992    0.998377      0.997998\n",
      "recall       1.000000    0.994764  0.997992    0.997382      0.997992\n",
      "f1-score     0.998374    0.997375  0.997992    0.997875      0.997991\n",
      "support    307.000000  191.000000  0.997992  498.000000    498.000000\n",
      "\n",
      "Accuracy of Decision Tree classifier on training set: 99.80%\n",
      "Accuracy: 99.8\n",
      "True Positive: 99.68 %\n",
      "False Positive: 0.0 %\n",
      "True Negative: 100.0 %\n",
      "False Negative: 0.32 %\n",
      "Precision: 100.0 %\n",
      "Recall: 99.68 %\n",
      "F1-Score: 99.84 %\n",
      "Positive Support: 308\n",
      "Negative Support: 190\n",
      "===============================================================================\n",
      "Tree with max depth of 15\n",
      "               0      1  accuracy  macro avg  weighted avg\n",
      "precision    1.0    1.0       1.0        1.0           1.0\n",
      "recall       1.0    1.0       1.0        1.0           1.0\n",
      "f1-score     1.0    1.0       1.0        1.0           1.0\n",
      "support    307.0  191.0       1.0      498.0         498.0\n",
      "\n",
      "Accuracy of Decision Tree classifier on training set: 100.00%\n",
      "Accuracy: 100.0\n",
      "True Positive: 100.0 %\n",
      "False Positive: 0.0 %\n",
      "True Negative: 100.0 %\n",
      "False Negative: 0.0 %\n",
      "Precision: 100.0 %\n",
      "Recall: 100.0 %\n",
      "F1-Score: 100.0 %\n",
      "Positive Support: 307\n",
      "Negative Support: 191\n",
      "===============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Yay! It's looping season!\n",
    "\n",
    "for i in range(1, 16):\n",
    "    # Train the model\n",
    "    classifier = DecisionTreeClassifier(max_depth= i , random_state=123)\n",
    "    \n",
    "    # Fit the model \n",
    "    classifier = classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Make Predictions\n",
    "    # This is where the model makes predictions, based on training set obeservations\n",
    "    y_predictions = classifier.predict(X_train)\n",
    "    y_predictions[0:5]\n",
    "\n",
    "    # Produce the classification report on the actual y values and this model's predicted y values\n",
    "    report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "    print(\"Tree with max depth of\", i )\n",
    "    print(pd.DataFrame(report))\n",
    "    print()\n",
    "    \n",
    "    # Evaluate the Model\n",
    "    print('Accuracy of Decision Tree classifier on training set: {:.2f}%'\n",
    "          .format(classifier.score(X_train, y_train) * 100 ))\n",
    "    \n",
    "    # Confusion Matrix \n",
    "    pd.DataFrame(confusion_matrix(y_train, y_predictions))\n",
    "    \n",
    "    # Classification Report \n",
    "    report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "    pd.DataFrame(report).T\n",
    "    \n",
    "    # Assign values from Confusion Matrix:\n",
    "    TP = confusion_matrix(y_train, y_predictions)[0][0]\n",
    "    FP = confusion_matrix(y_train, y_predictions)[0][1]\n",
    "    FN = confusion_matrix(y_train, y_predictions)[1][0]\n",
    "    TN = confusion_matrix(y_train, y_predictions)[1][1]\n",
    "\n",
    "    # Computations:\n",
    "    accuracy = (TP + TN)/(TP + FP + FN + TN)\n",
    "    print(\"Accuracy:\", round(accuracy*100,2))\n",
    "\n",
    "    true_positive = TP/(TP+FN)\n",
    "    print(\"True Positive:\", round(true_positive*100, 2) , \"%\")\n",
    "\n",
    "    false_positive = FP/(FP+TN)\n",
    "    print(\"False Positive:\", round(false_positive*100, 2) , \"%\")\n",
    "\n",
    "    true_negative = TN/(TN+FP)\n",
    "    print(\"True Negative:\", round(true_negative*100, 2) , \"%\")\n",
    "\n",
    "    false_negative = FN/(FN+TP)\n",
    "    print(\"False Negative:\", round(false_negative*100, 2) , \"%\")\n",
    "\n",
    "    precision = TP/(TP+FP)\n",
    "    print(\"Precision:\", round(precision*100, 2) , \"%\")\n",
    "\n",
    "    recall = TP/(TP+FN)\n",
    "    print(\"Recall:\", round(recall*100, 2) , \"%\")\n",
    "\n",
    "    # f1-score: The balanced harmonic mean of Recall and Precision, giving both metrics equal weight. \n",
    "    # The higher the F-Measure is, the better. \n",
    "    f1_score = 2*(precision*recall)/(precision+recall)\n",
    "    print(\"F1-Score:\", round(f1_score*100, 2) , \"%\")\n",
    "\n",
    "    # Support: number of occurrences of each class in where y is true.\n",
    "    pos_support = TP + FN\n",
    "    print(\"Positive Support:\", pos_support)\n",
    "\n",
    "    neg_support = FP + TN\n",
    "    print(\"Negative Support:\", neg_support)\n",
    "\n",
    "    print(\"===============================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d230d4",
   "metadata": {},
   "source": [
    "### 6. Which model performs better on your in-sample data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040cb97d",
   "metadata": {},
   "source": [
    "\n",
    "> <b>Any max depth >= 15 has a accuracy of 100%</b>\n",
    ">\n",
    "> <b>So if I wanted to avoid overfitting I might go more with a max depth of 11, where the accuracy is still 98.19%</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7820b71",
   "metadata": {},
   "source": [
    "\n",
    "### 7. Which model performs best on your out-of-sample data, the validate set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e984ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree with max depth of 1\n",
      "                    0          1  accuracy   macro avg  weighted avg\n",
      "precision    0.823529   0.743590  0.794393    0.783560      0.792898\n",
      "recall       0.848485   0.707317  0.794393    0.777901      0.794393\n",
      "f1-score     0.835821   0.725000  0.794393    0.780410      0.793357\n",
      "support    132.000000  82.000000  0.794393  214.000000    214.000000\n",
      "\n",
      "Accuracy of Decision Tree classifier on training set: 79.44%\n",
      "Accuracy: 79.44\n",
      "True Positive: 82.35 %\n",
      "False Positive: 25.64 %\n",
      "True Negative: 74.36 %\n",
      "False Negative: 17.65 %\n",
      "Precision: 84.85 %\n",
      "Recall: 82.35 %\n",
      "F1-Score: 83.58 %\n",
      "Positive Support: 136\n",
      "Negative Support: 78\n",
      "===============================================================================\n",
      "Tree with max depth of 2\n",
      "                    0          1  accuracy   macro avg  weighted avg\n",
      "precision    0.764706   0.954545  0.803738    0.859626      0.837448\n",
      "recall       0.984848   0.512195  0.803738    0.748522      0.803738\n",
      "f1-score     0.860927   0.666667  0.803738    0.763797      0.786491\n",
      "support    132.000000  82.000000  0.803738  214.000000    214.000000\n",
      "\n",
      "Accuracy of Decision Tree classifier on training set: 80.37%\n",
      "Accuracy: 80.37\n",
      "True Positive: 76.47 %\n",
      "False Positive: 4.55 %\n",
      "True Negative: 95.45 %\n",
      "False Negative: 23.53 %\n",
      "Precision: 98.48 %\n",
      "Recall: 76.47 %\n",
      "F1-Score: 86.09 %\n",
      "Positive Support: 170\n",
      "Negative Support: 44\n",
      "===============================================================================\n",
      "Tree with max depth of 3\n",
      "                    0          1  accuracy   macro avg  weighted avg\n",
      "precision    0.815789   0.870968  0.831776    0.843379      0.836933\n",
      "recall       0.939394   0.658537  0.831776    0.798965      0.831776\n",
      "f1-score     0.873239   0.750000  0.831776    0.811620      0.826017\n",
      "support    132.000000  82.000000  0.831776  214.000000    214.000000\n",
      "\n",
      "Accuracy of Decision Tree classifier on training set: 83.18%\n",
      "Accuracy: 83.18\n",
      "True Positive: 81.58 %\n",
      "False Positive: 12.9 %\n",
      "True Negative: 87.1 %\n",
      "False Negative: 18.42 %\n",
      "Precision: 93.94 %\n",
      "Recall: 81.58 %\n",
      "F1-Score: 87.32 %\n",
      "Positive Support: 152\n",
      "Negative Support: 62\n",
      "===============================================================================\n",
      "Tree with max depth of 4\n",
      "                    0          1  accuracy   macro avg  weighted avg\n",
      "precision    0.860140   0.873239  0.864486    0.866690      0.865159\n",
      "recall       0.931818   0.756098  0.864486    0.843958      0.864486\n",
      "f1-score     0.894545   0.810458  0.864486    0.852501      0.862325\n",
      "support    132.000000  82.000000  0.864486  214.000000    214.000000\n",
      "\n",
      "Accuracy of Decision Tree classifier on training set: 86.45%\n",
      "Accuracy: 86.45\n",
      "True Positive: 86.01 %\n",
      "False Positive: 12.68 %\n",
      "True Negative: 87.32 %\n",
      "False Negative: 13.99 %\n",
      "Precision: 93.18 %\n",
      "Recall: 86.01 %\n",
      "F1-Score: 89.45 %\n",
      "Positive Support: 143\n",
      "Negative Support: 71\n",
      "===============================================================================\n",
      "Tree with max depth of 5\n",
      "                    0          1  accuracy   macro avg  weighted avg\n",
      "precision    0.875862   0.927536  0.892523    0.901699      0.895662\n",
      "recall       0.962121   0.780488  0.892523    0.871305      0.892523\n",
      "f1-score     0.916968   0.847682  0.892523    0.882325      0.890419\n",
      "support    132.000000  82.000000  0.892523  214.000000    214.000000\n",
      "\n",
      "Accuracy of Decision Tree classifier on training set: 89.25%\n",
      "Accuracy: 89.25\n",
      "True Positive: 87.59 %\n",
      "False Positive: 7.25 %\n",
      "True Negative: 92.75 %\n",
      "False Negative: 12.41 %\n",
      "Precision: 96.21 %\n",
      "Recall: 87.59 %\n",
      "F1-Score: 91.7 %\n",
      "Positive Support: 145\n",
      "Negative Support: 69\n",
      "===============================================================================\n",
      "Tree with max depth of 6\n",
      "                    0          1  accuracy   macro avg  weighted avg\n",
      "precision    0.885135   0.984848  0.915888    0.934992      0.923343\n",
      "recall       0.992424   0.792683  0.915888    0.892554      0.915888\n",
      "f1-score     0.935714   0.878378  0.915888    0.907046      0.913744\n",
      "support    132.000000  82.000000  0.915888  214.000000    214.000000\n",
      "\n",
      "Accuracy of Decision Tree classifier on training set: 91.59%\n",
      "Accuracy: 91.59\n",
      "True Positive: 88.51 %\n",
      "False Positive: 1.52 %\n",
      "True Negative: 98.48 %\n",
      "False Negative: 11.49 %\n",
      "Precision: 99.24 %\n",
      "Recall: 88.51 %\n",
      "F1-Score: 93.57 %\n",
      "Positive Support: 148\n",
      "Negative Support: 66\n",
      "===============================================================================\n",
      "Tree with max depth of 7\n",
      "                    0          1  accuracy   macro avg  weighted avg\n",
      "precision    0.909722   0.985714  0.934579    0.947718      0.938841\n",
      "recall       0.992424   0.841463  0.934579    0.916944      0.934579\n",
      "f1-score     0.949275   0.907895  0.934579    0.928585      0.933419\n",
      "support    132.000000  82.000000  0.934579  214.000000    214.000000\n",
      "\n",
      "Accuracy of Decision Tree classifier on training set: 93.46%\n",
      "Accuracy: 93.46\n",
      "True Positive: 90.97 %\n",
      "False Positive: 1.43 %\n",
      "True Negative: 98.57 %\n",
      "False Negative: 9.03 %\n",
      "Precision: 99.24 %\n",
      "Recall: 90.97 %\n",
      "F1-Score: 94.93 %\n",
      "Positive Support: 144\n",
      "Negative Support: 70\n",
      "===============================================================================\n",
      "Tree with max depth of 8\n",
      "                    0          1  accuracy   macro avg  weighted avg\n",
      "precision    0.955556   0.962025  0.957944    0.958790      0.958035\n",
      "recall       0.977273   0.926829  0.957944    0.952051      0.957944\n",
      "f1-score     0.966292   0.944099  0.957944    0.955196      0.957788\n",
      "support    132.000000  82.000000  0.957944  214.000000    214.000000\n",
      "\n",
      "Accuracy of Decision Tree classifier on training set: 95.79%\n",
      "Accuracy: 95.79\n",
      "True Positive: 95.56 %\n",
      "False Positive: 3.8 %\n",
      "True Negative: 96.2 %\n",
      "False Negative: 4.44 %\n",
      "Precision: 97.73 %\n",
      "Recall: 95.56 %\n",
      "F1-Score: 96.63 %\n",
      "Positive Support: 135\n",
      "Negative Support: 79\n",
      "===============================================================================\n",
      "Tree with max depth of 9\n",
      "                    0          1  accuracy   macro avg  weighted avg\n",
      "precision    0.956204   0.987013   0.96729    0.971609      0.968010\n",
      "recall       0.992424   0.926829   0.96729    0.959627      0.967290\n",
      "f1-score     0.973978   0.955975   0.96729    0.964976      0.967079\n",
      "support    132.000000  82.000000   0.96729  214.000000    214.000000\n",
      "\n",
      "Accuracy of Decision Tree classifier on training set: 96.73%\n",
      "Accuracy: 96.73\n",
      "True Positive: 95.62 %\n",
      "False Positive: 1.3 %\n",
      "True Negative: 98.7 %\n",
      "False Negative: 4.38 %\n",
      "Precision: 99.24 %\n",
      "Recall: 95.62 %\n",
      "F1-Score: 97.4 %\n",
      "Positive Support: 137\n",
      "Negative Support: 77\n",
      "===============================================================================\n",
      "Tree with max depth of 10\n",
      "                    0          1  accuracy   macro avg  weighted avg\n",
      "precision    0.956522   1.000000  0.971963    0.978261      0.973182\n",
      "recall       1.000000   0.926829  0.971963    0.963415      0.971963\n",
      "f1-score     0.977778   0.962025  0.971963    0.969902      0.971742\n",
      "support    132.000000  82.000000  0.971963  214.000000    214.000000\n",
      "\n",
      "Accuracy of Decision Tree classifier on training set: 97.20%\n",
      "Accuracy: 97.2\n",
      "True Positive: 95.65 %\n",
      "False Positive: 0.0 %\n",
      "True Negative: 100.0 %\n",
      "False Negative: 4.35 %\n",
      "Precision: 100.0 %\n",
      "Recall: 95.65 %\n",
      "F1-Score: 97.78 %\n",
      "Positive Support: 138\n",
      "Negative Support: 76\n",
      "===============================================================================\n",
      "Tree with max depth of 11\n",
      "                    0          1  accuracy   macro avg  weighted avg\n",
      "precision    0.992424   0.987805  0.990654    0.990115      0.990654\n",
      "recall       0.992424   0.987805  0.990654    0.990115      0.990654\n",
      "f1-score     0.992424   0.987805  0.990654    0.990115      0.990654\n",
      "support    132.000000  82.000000  0.990654  214.000000    214.000000\n",
      "\n",
      "Accuracy of Decision Tree classifier on training set: 99.07%\n",
      "Accuracy: 99.07\n",
      "True Positive: 99.24 %\n",
      "False Positive: 1.22 %\n",
      "True Negative: 98.78 %\n",
      "False Negative: 0.76 %\n",
      "Precision: 99.24 %\n",
      "Recall: 99.24 %\n",
      "F1-Score: 99.24 %\n",
      "Positive Support: 132\n",
      "Negative Support: 82\n",
      "===============================================================================\n",
      "Tree with max depth of 12\n",
      "               0     1  accuracy  macro avg  weighted avg\n",
      "precision    1.0   1.0       1.0        1.0           1.0\n",
      "recall       1.0   1.0       1.0        1.0           1.0\n",
      "f1-score     1.0   1.0       1.0        1.0           1.0\n",
      "support    132.0  82.0       1.0      214.0         214.0\n",
      "\n",
      "Accuracy of Decision Tree classifier on training set: 100.00%\n",
      "Accuracy: 100.0\n",
      "True Positive: 100.0 %\n",
      "False Positive: 0.0 %\n",
      "True Negative: 100.0 %\n",
      "False Negative: 0.0 %\n",
      "Precision: 100.0 %\n",
      "Recall: 100.0 %\n",
      "F1-Score: 100.0 %\n",
      "Positive Support: 132\n",
      "Negative Support: 82\n",
      "===============================================================================\n",
      "Tree with max depth of 13\n",
      "               0     1  accuracy  macro avg  weighted avg\n",
      "precision    1.0   1.0       1.0        1.0           1.0\n",
      "recall       1.0   1.0       1.0        1.0           1.0\n",
      "f1-score     1.0   1.0       1.0        1.0           1.0\n",
      "support    132.0  82.0       1.0      214.0         214.0\n",
      "\n",
      "Accuracy of Decision Tree classifier on training set: 100.00%\n",
      "Accuracy: 100.0\n",
      "True Positive: 100.0 %\n",
      "False Positive: 0.0 %\n",
      "True Negative: 100.0 %\n",
      "False Negative: 0.0 %\n",
      "Precision: 100.0 %\n",
      "Recall: 100.0 %\n",
      "F1-Score: 100.0 %\n",
      "Positive Support: 132\n",
      "Negative Support: 82\n",
      "===============================================================================\n",
      "Tree with max depth of 14\n",
      "               0     1  accuracy  macro avg  weighted avg\n",
      "precision    1.0   1.0       1.0        1.0           1.0\n",
      "recall       1.0   1.0       1.0        1.0           1.0\n",
      "f1-score     1.0   1.0       1.0        1.0           1.0\n",
      "support    132.0  82.0       1.0      214.0         214.0\n",
      "\n",
      "Accuracy of Decision Tree classifier on training set: 100.00%\n",
      "Accuracy: 100.0\n",
      "True Positive: 100.0 %\n",
      "False Positive: 0.0 %\n",
      "True Negative: 100.0 %\n",
      "False Negative: 0.0 %\n",
      "Precision: 100.0 %\n",
      "Recall: 100.0 %\n",
      "F1-Score: 100.0 %\n",
      "Positive Support: 132\n",
      "Negative Support: 82\n",
      "===============================================================================\n",
      "Tree with max depth of 15\n",
      "               0     1  accuracy  macro avg  weighted avg\n",
      "precision    1.0   1.0       1.0        1.0           1.0\n",
      "recall       1.0   1.0       1.0        1.0           1.0\n",
      "f1-score     1.0   1.0       1.0        1.0           1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "support    132.0  82.0       1.0      214.0         214.0\n",
      "\n",
      "Accuracy of Decision Tree classifier on training set: 100.00%\n",
      "Accuracy: 100.0\n",
      "True Positive: 100.0 %\n",
      "False Positive: 0.0 %\n",
      "True Negative: 100.0 %\n",
      "False Negative: 0.0 %\n",
      "Precision: 100.0 %\n",
      "Recall: 100.0 %\n",
      "F1-Score: 100.0 %\n",
      "Positive Support: 132\n",
      "Negative Support: 82\n",
      "===============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Yay! It's looping season!\n",
    "\n",
    "for i in range(1, 16):\n",
    "    # Train the model\n",
    "    classifier = DecisionTreeClassifier(max_depth= i , random_state=123)\n",
    "    \n",
    "    # Fit the model \n",
    "    classifier = classifier.fit(X_validate, y_validate)\n",
    "\n",
    "    # Make Predictions\n",
    "    # This is where the model makes predictions, based on training set obeservations\n",
    "    y_predictions = classifier.predict(X_validate)\n",
    "    y_predictions[0:5]\n",
    "\n",
    "    # Produce the classification report on the actual y values and this model's predicted y values\n",
    "    report = classification_report(y_validate, y_predictions, output_dict=True)\n",
    "    print(\"Tree with max depth of\", i )\n",
    "    print(pd.DataFrame(report))\n",
    "    print()\n",
    "    \n",
    "    # Evaluate the Model\n",
    "    print('Accuracy of Decision Tree classifier on training set: {:.2f}%'\n",
    "          .format(classifier.score(X_validate, y_validate) * 100 ))\n",
    "    \n",
    "    # Confusion Matrix \n",
    "    pd.DataFrame(confusion_matrix(y_validate, y_predictions))\n",
    "    \n",
    "    # Classification Report \n",
    "    report = classification_report(y_validate, y_predictions, output_dict=True)\n",
    "    pd.DataFrame(report).T\n",
    "    \n",
    "    # Assign values from Confusion Matrix:\n",
    "    TP = confusion_matrix(y_validate, y_predictions)[0][0]\n",
    "    FP = confusion_matrix(y_validate, y_predictions)[0][1]\n",
    "    FN = confusion_matrix(y_validate, y_predictions)[1][0]\n",
    "    TN = confusion_matrix(y_validate, y_predictions)[1][1]\n",
    "\n",
    "    # Computations:\n",
    "    accuracy = (TP + TN)/(TP + FP + FN + TN)\n",
    "    print(\"Accuracy:\", round(accuracy*100,2))\n",
    "\n",
    "    true_positive = TP/(TP+FN)\n",
    "    print(\"True Positive:\", round(true_positive*100, 2) , \"%\")\n",
    "\n",
    "    false_positive = FP/(FP+TN)\n",
    "    print(\"False Positive:\", round(false_positive*100, 2) , \"%\")\n",
    "\n",
    "    true_negative = TN/(TN+FP)\n",
    "    print(\"True Negative:\", round(true_negative*100, 2) , \"%\")\n",
    "\n",
    "    false_negative = FN/(FN+TP)\n",
    "    print(\"False Negative:\", round(false_negative*100, 2) , \"%\")\n",
    "\n",
    "    precision = TP/(TP+FP)\n",
    "    print(\"Precision:\", round(precision*100, 2) , \"%\")\n",
    "\n",
    "    recall = TP/(TP+FN)\n",
    "    print(\"Recall:\", round(recall*100, 2) , \"%\")\n",
    "\n",
    "    # f1-score: The balanced harmonic mean of Recall and Precision, giving both metrics equal weight. \n",
    "    # The higher the F-Measure is, the better. \n",
    "    f1_score = 2*(precision*recall)/(precision+recall)\n",
    "    print(\"F1-Score:\", round(f1_score*100, 2) , \"%\")\n",
    "\n",
    "    # Support: number of occurrences of each class in where y is true.\n",
    "    pos_support = TP + FN\n",
    "    print(\"Positive Support:\", pos_support)\n",
    "\n",
    "    neg_support = FP + TN\n",
    "    print(\"Negative Support:\", neg_support)\n",
    "\n",
    "    print(\"===============================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0025479",
   "metadata": {},
   "source": [
    "\n",
    "> <b>Any max depth >= 12 has a accuracy of 100%</b>\n",
    ">\n",
    "> <b>So if I wanted to avoid overfitting I might go more with a max depth of 1, where the accuracy is still 97.20%</b>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
